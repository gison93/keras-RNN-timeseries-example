{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import warnings\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import autocorrelation_plot\n",
    "from numpy import newaxis\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Sequential\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' #Hide messy TensorFlow warnings\n",
    "warnings.filterwarnings(\"ignore\") #Hide messy Numpy warnings\n",
    "sqlalchemy_conn_string = 'postgresql://test:test@localhost:5432/test' # connection string for your db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "engine = create_engine(sqlalchemy_conn_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(sequence_length, normalise_window=True, train_fraction=0.9):\n",
    "    # rewrite the query to pull the data you want to predict.\n",
    "    # it should be an ordered series. \n",
    "    # If you have some dates that are zero, don't forget to use a date sequence to fix it.\n",
    "    query = '''\n",
    "        select count(*) as numbers\n",
    "        from mytable\n",
    "        group by created::date\n",
    "        order by created::date;\n",
    "    '''\n",
    "    numbers = pd.read_sql_query(query, engine)\n",
    "    data = numbers.as_matrix(columns=['numbers'])\n",
    "\n",
    "    sequence_length = sequence_length + 1\n",
    "    result = []\n",
    "    for index in range(len(data) - sequence_length):\n",
    "        result.append(data[index: index + sequence_length])\n",
    "    print('> N Samples = {}'.format(len(result)))\n",
    "    \n",
    "    if normalise_window:\n",
    "        result, norms = normalise_windows(result)\n",
    "\n",
    "    result = np.array(result)\n",
    "    n_training_rows = round(train_fraction * result.shape[0])\n",
    "    \n",
    "    train = result[:int(n_training_rows), :]\n",
    "    np.random.shuffle(train)\n",
    "    x_train = train[:, :-1]\n",
    "    y_train = train[:, -1]\n",
    "    nrm_train = norms[:int(n_training_rows)]\n",
    "    \n",
    "    test = result[int(n_training_rows):, :]\n",
    "    x_test = test[:, :-1]\n",
    "    y_test = test[:, -1]\n",
    "    nrm_test = norms[int(n_training_rows):]\n",
    "    \n",
    "    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
    "    x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))  \n",
    "    \n",
    "    print('> X Train shape= {}'.format(x_train.shape))\n",
    "    print('> Y Train shape= {}'.format(y_train.shape))\n",
    "    print('> X Test shape = {}'.format(x_test.shape))\n",
    "    print('> Y Test shape = {}'.format(y_test.shape))\n",
    "\n",
    "    return [x_train, y_train, x_test, y_test, nrm_test, nrm_train]\n",
    "\n",
    "def normalise_windows(window_data):\n",
    "    # scaled and shifted data.\n",
    "    normalised_data = []\n",
    "    # norms are used to put the data back to it's original range.\n",
    "    norms = []\n",
    "    for window in window_data:\n",
    "        norms.append(float(window[0]))\n",
    "        normalised_window = [((float(p) / float(window[0])) - 1) for p in window]\n",
    "        normalised_data.append(normalised_window)\n",
    "    return normalised_data, norms\n",
    "\n",
    "def denormalise_windows(normalised_data, norms):\n",
    "    # inverse operation for normalise_windows\n",
    "    data = []\n",
    "    for window, nrm in zip(normalised_data, norms):\n",
    "        data_window = (window+1.0)*nrm \n",
    "        data.append(data_window)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model(layers):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(LSTM(\n",
    "        input_shape=(layers[1], layers[0]),\n",
    "        output_dim=layers[1],\n",
    "        return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(LSTM(\n",
    "        layers[2],\n",
    "        return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(LSTM(\n",
    "        layers[3],\n",
    "        return_sequences=False))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(\n",
    "        output_dim=layers[3]))\n",
    "    model.add(Activation(\"linear\"))\n",
    "\n",
    "    start = time.time()\n",
    "    model.compile(loss=\"mse\", optimizer=\"rmsprop\")\n",
    "    print(\"> Compilation Time : \", time.time() - start)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_sequences_multiple(model, data, prediction_offset, prediction_length):\n",
    "    # we'll insert the new prediction into the current frame at the end.\n",
    "    end_of_sample_index = data[0].shape[0]-1\n",
    "    prediction_seqs = []\n",
    "    for i in range(int(len(data)/prediction_offset)):\n",
    "        curr_frame = data[i*prediction_offset]\n",
    "        predicted = []\n",
    "        for j in range(prediction_length):\n",
    "            predicted.append(model.predict(curr_frame[newaxis,:,:])[0,0])\n",
    "            curr_frame = curr_frame[1:]\n",
    "            curr_frame = np.insert(curr_frame, [end_of_sample_index], predicted[-1], axis=0)\n",
    "        prediction_seqs.append(predicted)\n",
    "    return prediction_seqs\n",
    "\n",
    "def plot_results_multiple(predicted_data, true_data, y_norms, window_len):\n",
    "    fig = plt.figure(facecolor='white', figsize=(16,8))\n",
    "    ax = fig.add_subplot(111)\n",
    "    # put it back into the original units\n",
    "    ax.plot(denormalise_windows(true_data, y_norms), label='True Data')\n",
    "    #Pad the list of predictions to shift it in the graph to it's correct start\n",
    "    for i, data in enumerate(predicted_data):\n",
    "        padding = [None for p in range(i * window_len)]\n",
    "        # inline denormalization\n",
    "        plt.plot(padding + [y_norms[i * window_len]*(x+1.0) for x in data], label='Prediction')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "global_start_time = time.time()\n",
    "epochs  = 400\n",
    "\n",
    "sequence_length = 28\n",
    "prediction_length = 7\n",
    "prediction_offset = 7\n",
    "\n",
    "print('> Loading data... ')\n",
    "\n",
    "X_train, y_train, X_test, y_test, nrm_test, nrm_train = load_data(sequence_length, normalise_window=True)\n",
    "\n",
    "print('> Data Loaded. Compiling...')\n",
    "\n",
    "model = build_model([1, sequence_length, int(sequence_length*2), int(sequence_length*4), 1])\n",
    "\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=25,\n",
    "    nb_epoch=epochs,\n",
    "    validation_split=0.05,\n",
    "    verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot the predictions on the test set\n",
    "predictions = predict_sequences_multiple(model, X_test, prediction_offset, prediction_length)\n",
    "print('> Training duration (s) : ', time.time() - global_start_time)\n",
    "plot_results_multiple(predictions, y_test, nrm_test, prediction_offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the predictions on the training set\n",
    "predictions = predict_sequences_multiple(model, X_train, prediction_offset, prediction_length)\n",
    "plot_results_multiple(predictions, y_train, nrm_train, prediction_offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
